{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brown & Philips et. al \"Semi-automated production of cell-free biosensors\" Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile excel**\n",
    "an excel spreadsheet that processes kinetic data from biosensor experiment. Reaction data was manually normalized and placed in an excel spreadsheet before python processing. Output provides half max signal, max signal, and time to half max signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Excel spreadsheet, Change directory path for different data\n",
    "excel_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_FRS_Compiled_Data.xlsx'\n",
    "\n",
    "# Open the Excel file\n",
    "xls = pd.ExcelFile(excel_file)\n",
    "\n",
    "# Create a new Excel writer to save the outputs\n",
    "output_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_Output_FRS_Compiled_Data.xlsx'\n",
    "output_writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
    "\n",
    "# Loop through each sheet in the Excel file\n",
    "for sheet_name in xls.sheet_names:\n",
    "    print(f\"Processing sheet: {sheet_name}\")\n",
    "\n",
    "    # Read the data from the current sheet\n",
    "    data = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "\n",
    "    # Determine column headers\n",
    "    column_headers = data.columns.tolist()\n",
    "    time_column = column_headers[0]  # Assuming the first column is the time column\n",
    "\n",
    "    # Convert columns to numeric values\n",
    "    for column in column_headers[1:]:\n",
    "        data[column] = pd.to_numeric(data[column], errors='coerce')\n",
    "\n",
    "    # Find the minimum and maximum signal values, and calculate half-maximum value for each column\n",
    "    half_max_values = {}\n",
    "    max_values = {}\n",
    "    time_to_half_max = {}\n",
    "    for column in column_headers[1:]:\n",
    "        min_signal = data[column].min()\n",
    "        max_signal = data[column].max()\n",
    "        half_max_signal = (min_signal + max_signal) / 2\n",
    "\n",
    "        signal_values = data[column].values\n",
    "        time_values = data[time_column].values\n",
    "\n",
    "        # Initialize variables\n",
    "        half_max_time = None\n",
    "        max_signal_value = max_signal  # Initialize with the maximum value\n",
    "        prev_signal = signal_values[0]\n",
    "        crossing_indices = []\n",
    "\n",
    "        # Loop through the data to find crossing indices and calculate the maximum signal\n",
    "        for i in range(1, len(signal_values)):\n",
    "            if signal_values[i] > max_signal_value:\n",
    "                max_signal_value = signal_values[i]\n",
    "            if prev_signal <= half_max_signal <= signal_values[i] or prev_signal >= half_max_signal >= signal_values[i]:\n",
    "                crossing_indices.append(i)\n",
    "\n",
    "            prev_signal = signal_values[i]\n",
    "\n",
    "        if len(crossing_indices) > 0:\n",
    "            last_crossing_index = crossing_indices[-1]\n",
    "            x1 = time_values[last_crossing_index - 1]\n",
    "            x2 = time_values[last_crossing_index]\n",
    "            y1 = signal_values[last_crossing_index - 1]\n",
    "            y2 = signal_values[last_crossing_index]\n",
    "            half_max_time = x1 + ((x2 - x1) * (half_max_signal - y1) / (y2 - y1))\n",
    "\n",
    "        half_max_values[column] = half_max_signal\n",
    "        max_values[column] = max_signal_value\n",
    "        time_to_half_max[column] = half_max_time\n",
    "\n",
    "    # Create dataframes from the dictionaries\n",
    "    half_max_df = pd.DataFrame(list(half_max_values.items()), columns=['Column', 'Half-Maximum Signal Value'])\n",
    "    max_df = pd.DataFrame(list(max_values.items()), columns=['Column', 'Maximum Signal Value'])\n",
    "    time_to_half_max_df = pd.DataFrame(list(time_to_half_max.items()), columns=['Column', 'Time to Half-Maximum'])\n",
    "\n",
    "    # Save the dataframes to the Excel file\n",
    "    half_max_df.to_excel(output_writer, sheet_name=f\"{sheet_name}_Half_Max\", index=False)\n",
    "    max_df.to_excel(output_writer, sheet_name=f\"{sheet_name}_Max\", index=False)\n",
    "    time_to_half_max_df.to_excel(output_writer, sheet_name=f\"{sheet_name}_Time_to_Half_Max\", index=False)\n",
    "\n",
    "# Save the Excel file with the outputs\n",
    "output_writer.save()\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorization of 384 well plate based on reaction induction conditions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the compiled data and categorizes the wells of a 384 well plate, in this experiment, rehydration was carried out using an interleaved signal format with High (H) concentration NaF (1mM), Medium (M) concentration NaF (0.25mM), and Low (L) concentration NaF (0 mM). Four 96 well plates were constructed using the rehydration format HML, LHM, MLH, then HML, where these concentrations of NaF were added to each column of the 96 well plate repeating 4 times per plate (ex. column 1=H, 2=M, 3=L, 4=H, 5=M, 6=L, until the plate is fully rehydrated).This was to account for distribution effects imparted by the robot. All 4 96 well plates are then plated in a 384 well plate in quadrants.  The code used here then categorizes each biosensor reaction based on their 384 well plate position given a label H, M, or L, depending on the rehydration condition. This output can then be used to look at distributions of each hydrated condition graphically, using H, M, or L to distribute the populations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the previously generated output file\n",
    "output_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_Output_FRS_Compiled_Data.xlsx'\n",
    "output_reader = pd.ExcelFile(output_file)\n",
    "\n",
    "# Create a new Excel writer to save the updated data\n",
    "updated_output_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_Updated_Output_FRS_Compiled_Data.xlsx'\n",
    "output_writer = pd.ExcelWriter(updated_output_file, engine='xlsxwriter')\n",
    "\n",
    "# Define a function to categorize columns based on the pattern\n",
    "def categorize_column(column_name):\n",
    "    if len(column_name) >= 2 and column_name[0] in 'ABCDEFGH':\n",
    "        column_number = column_name[1:]\n",
    "        if column_number.isdigit() or (column_number[:-1].isdigit() and int(column_number[:-1]) >= 10):\n",
    "            column_number = int(column_number)\n",
    "            if (column_number >= 1 and column_number <= 12):\n",
    "                if column_number % 3 == 1:\n",
    "                    return 'H'\n",
    "                elif column_number % 3 == 2:\n",
    "                    return 'M'\n",
    "                else:\n",
    "                    return 'L'\n",
    "            elif (column_number >= 13 and column_number <= 24):\n",
    "                if column_number % 3 == 1:\n",
    "                    return 'L'\n",
    "                elif column_number % 3 == 2:\n",
    "                    return 'H'\n",
    "                else:\n",
    "                    return 'M'\n",
    "    elif len(column_name) >= 2 and column_name[0] in 'IJKLMNOP':\n",
    "        column_number = column_name[1:]\n",
    "        if column_number.isdigit() or (column_number[:-1].isdigit() and int(column_number[:-1]) >= 10):\n",
    "            column_number = int(column_number)\n",
    "            if (column_number >= 1 and column_number <= 12):\n",
    "                if column_number % 3 == 1:\n",
    "                    return 'M'\n",
    "                elif column_number % 3 == 2:\n",
    "                    return 'L'\n",
    "                else:\n",
    "                    return 'H'\n",
    "            elif (column_number >= 13 and column_number <= 24):\n",
    "                if column_number % 3 == 1:\n",
    "                    return 'H'\n",
    "                elif column_number % 3 == 2:\n",
    "                    return 'M'\n",
    "                else:\n",
    "                    return 'L'\n",
    "    return ''\n",
    "\n",
    "# Loop through each sheet in the output file\n",
    "for sheet_name in output_reader.sheet_names:\n",
    "    df = output_reader.parse(sheet_name)\n",
    "\n",
    "    # Add a new column with category labels based on the pattern\n",
    "    df['Category'] = df['Column'].apply(categorize_column)\n",
    "\n",
    "    # Save the updated data to a new sheet in the output_writer\n",
    "    df.to_excel(output_writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Save the updated Excel file with the category labels\n",
    "output_writer.save()\n",
    "print(f\"Updated results saved to {updated_output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WELL POSITION PLOTS** To assess distribution consistency accross the well positions over the four plates. This can be affected in part by experimenter rehydration error. Plots go from wells A1->P24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "output_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_Updated_Output_FRS_Compiled_Data.xlsx'\n",
    "output_reader = pd.ExcelFile(output_file)\n",
    "\n",
    "for sheet_name in output_reader.sheet_names:\n",
    "    # Read the sheet into a DataFrame\n",
    "    df = output_reader.parse(sheet_name, header=0)  # Assuming the first row is a header\n",
    "\n",
    "    # Check if there are at least 3 columns\n",
    "    if len(df.columns) < 3:\n",
    "        print(f\"Sheet {sheet_name} does not have at least 3 columns. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Extract the second and third columns\n",
    "    x = df.iloc[:, 1]  # Second column\n",
    "    y = df.iloc[:, 2]  # Third column\n",
    "\n",
    "    # Extract the alphanumeric values (e.g., 'A1', 'A2', 'B1')\n",
    "    alphanumeric = df.iloc[:, 0]  # Assuming the alphanumeric values are in the first column\n",
    "\n",
    "    # Create a figure\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Create a horizontal scatter plot with X-axis based on column one and 'H,' 'M,' and 'L' labels\n",
    "    sns.scatterplot(x=alphanumeric, y=x, hue=y, palette={'H': 'red', 'M': 'green', 'L': 'blue'})\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Alphanumeric Value (X-Axis)')\n",
    "    ax.set_ylabel('X-Axis Label')  # Switched axis label\n",
    "    ax.set_title(f'Scatter Plot for Sheet: {sheet_name}')\n",
    "    ax.legend(title='Density', labels=['H', 'M', 'L'])\n",
    "\n",
    "    # Show or save the plot as desired\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Swarm and Violing Plots** Shows the distribution of the populations separated by H, M, or L concentration conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates and saves swarm plots as svg files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "output_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_Updated_Output_FRS_Compiled_Data.xlsx'\n",
    "output_reader = pd.ExcelFile(output_file)\n",
    "\n",
    "# Custom color in RGB format (e.g., (0.1, 0.2, 0.5) for a blueish color)\n",
    "swarm_color_rgb = (0.53333, 1, 0.6862745098039216)\n",
    "\n",
    "output_folder = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2'  # Define the output folder path\n",
    "\n",
    "for sheet_name in output_reader.sheet_names:\n",
    "    # Read the sheet into a DataFrame\n",
    "    df = output_reader.parse(sheet_name, header=0)  # Assuming the first row is a header\n",
    "\n",
    "    # Check if there are at least 3 columns\n",
    "    if len(df.columns) < 3:\n",
    "        print(f\"Sheet {sheet_name} does not have at least 3 columns. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Extract the second and third columns\n",
    "    y = df.iloc[:, 1]  # Second column\n",
    "    x = df.iloc[:, 2]  # Third column\n",
    "\n",
    "    # Extract the categorical labels\n",
    "    labels = df.iloc[:, 2]  # Assuming the categorical labels are in the third column\n",
    "\n",
    "    # Set style to gray\n",
    "    sns.set(style=\"whitegrid\", palette=\"bone\")\n",
    "\n",
    "    # Define the desired order of categories\n",
    "    hue_order = ['L', 'M', 'H']\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(3, 2))\n",
    "\n",
    "    # Create a swarmplot for distribution of points with specified hue order\n",
    "    sns.swarmplot(x=x, y=y, hue=labels, hue_order=hue_order, color=swarm_color_rgb, alpha=1, size =3,  ax=ax, dodge = False)\n",
    "\n",
    "    plt.title(f'Swarm Plot: {sheet_name}')\n",
    "    plt.xlabel('NaF Condition')\n",
    "    plt.ylabel('MEF (uM FITC)')\n",
    "    plt.legend(title='Labels')\n",
    "\n",
    "    # Save the plot as an SVG file\n",
    "    output_filename = os.path.join(output_folder, f'{sheet_name}_swarm_plot.svg')\n",
    "    plt.savefig(output_filename, format='svg', bbox_inches='tight')\n",
    "    plt.close()  # Close the current figure to release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates violin plots for the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "output_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_Updated_Output_FRS_Compiled_Data.xlsx'\n",
    "output_reader = pd.ExcelFile(output_file)\n",
    "\n",
    "# Custom color in RGB format (e.g., (0.1, 0.2, 0.5) for a blueish color)\n",
    "outline_color_rgb = (0.53333, 1, 0.6862745098039216)\n",
    "\n",
    "output_folder = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2'  # Define the output folder path\n",
    "\n",
    "for sheet_name in output_reader.sheet_names:\n",
    "    # Read the sheet into a DataFrame\n",
    "    df = output_reader.parse(sheet_name, header=0)  # Assuming the first row is a header\n",
    "\n",
    "    # Check if there are at least 3 columns\n",
    "    if len(df.columns) < 3:\n",
    "        print(f\"Sheet {sheet_name} does not have at least 3 columns. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Extract the second and third columns\n",
    "    y = df.iloc[:, 1]  # Second column\n",
    "    x = df.iloc[:, 2]  # Third column\n",
    "\n",
    "    # Extract the categorical labels\n",
    "    labels = df.iloc[:, 2]  # Assuming the categorical labels are in the third column\n",
    "\n",
    "    # Set style to gray\n",
    "    sns.set(style=\"whitegrid\", palette=\"bone\")\n",
    "\n",
    "    # Define the desired order of categories\n",
    "    hue_order = ['L', 'M', 'H']\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(3, 2))\n",
    "\n",
    "    # Create a violin plot for distribution of points with specified hue order\n",
    "    sns.violinplot(x=x, y=y, hue=labels, hue_order=hue_order, ax=ax, dodge=False,\n",
    "                   linewidth=1.5, inner=None, palette=[outline_color_rgb], \n",
    "                   edgecolor=outline_color_rgb)\n",
    "\n",
    "    plt.title(f'Violin Plot: {sheet_name}')\n",
    "    plt.xlabel('NaF Condition')\n",
    "    plt.ylabel('MEF (uM FITC)')\n",
    "    plt.legend(title='Labels')\n",
    "\n",
    "    # Save the plot as an SVG file\n",
    "    output_filename = os.path.join(output_folder, f'{sheet_name}_violin_plot.svg')\n",
    "    plt.savefig(output_filename, format='svg', bbox_inches='tight')\n",
    "    plt.close()  # Close the current figure to release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Percentages Above Cutoffs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates an excel spreadsheet with the fraction of reactions above the given cutoffs. The thresholds were experimental data were given as Signal > Max Value of Signal in L, and Signal > 0.5 uM FITC for the experimental conditions. For the expected values, to meet Signal > Max Value of Signal in L both H = 1mM NaF and M = 0.25 mM NaF over the total number of reactions (H+M+L) is considered expected. For the 0.5uM FITC threshold, H=1mM NaF is expected to achieve this fluorescence under the given conditions, and the fraction is given as (H/(H+M+L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "output_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_Updated_Output_FRS_Compiled_Data.xlsx'\n",
    "\n",
    "# Read the \"max signal\" sheet\n",
    "df = pd.read_excel(output_file, sheet_name=\"Sheet1_Max\")\n",
    "\n",
    "# First calculation: Fraction of data higher than max value of category L\n",
    "# Get the maximum value of the category 'L'\n",
    "max_value_L = df[df['Category'] == 'L']['Maximum Signal Value'].max()\n",
    "\n",
    "# Calculate the fraction of data in \"Maximum Signal Values\" higher than max_value_L\n",
    "fraction_higher = (df['Maximum Signal Value'] > max_value_L).mean()\n",
    "\n",
    "# Calculate the expected fraction (all H and M values over the total)\n",
    "fraction_HM = df[df['Category'].isin(['H', 'M'])].shape[0] / df.shape[0]\n",
    "\n",
    "# Create a DataFrame with the calculated values for the first calculation\n",
    "data1 = pd.DataFrame({\n",
    "    'Fraction Higher': [fraction_higher],\n",
    "    'Expected Fraction (H and M over Total)': [fraction_HM]\n",
    "})\n",
    "\n",
    "# Second calculation: Fraction of data above 0.5\n",
    "# Calculate the fraction of data in \"Maximum Signal Values\" higher than 0.5\n",
    "fraction_above_0_5 = (df['Maximum Signal Value'] > 0.5).mean()\n",
    "\n",
    "# Calculate the expected fraction (H over the total of H, M, and L)\n",
    "total_HML = df[df['Category'].isin(['H', 'M', 'L'])].shape[0]\n",
    "fraction_H = df[df['Category'] == 'H'].shape[0] / total_HML\n",
    "\n",
    "# Create a DataFrame with the calculated values for the second calculation\n",
    "data2 = pd.DataFrame({\n",
    "    'Fraction Above 0.5': [fraction_above_0_5],\n",
    "    'Expected Fraction (H over H+M+L)': [fraction_H]\n",
    "})\n",
    "\n",
    "# Save the two DataFrames to a new Excel file with different sheets\n",
    "new_output_file = '/Users/dylan/LucksLab Dropbox/LucksLab/Lucks_Lab_Papers/In_Progress/77_CBC_Objective_3_Sensor_Scaleup/Supplemental_Information/Supporting Data and Python Files/Supp_Data_Figure_2/Figure_2_FRS_Percent_Expected_vs_Actual.xlsx'\n",
    "with pd.ExcelWriter(new_output_file) as writer:\n",
    "    data1.to_excel(writer, sheet_name='Fraction_Higher', index=False)\n",
    "    data2.to_excel(writer, sheet_name='Above_0_5', index=False)\n",
    "\n",
    "print(\"New Excel file with both sets of fractions created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
